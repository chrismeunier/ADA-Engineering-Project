{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First tries with LDA\n",
    "Try using spark lda but with gensim corpus processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark and gensim mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim import corpora\n",
    "from gensim.matutils import corpus2dense\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dictionary from gensim, each lemma will be assigned a number\n",
    "dictionary = corpora.Dictionary(line for line in wlp_bytext.rdd.map(lambda r: r[1]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dictionary object also have some useful informations stored in it\n",
    "print('Number of documents in corpus: \\t', dictionary.num_docs)\n",
    "print('Number of words in corpus: \\t', dictionary.num_pos)\n",
    "print('Number of tokens in dictionary: ', len(dictionary.token2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class that makes the gensim corpus object, \n",
    "#for now this is the only way I found to go from sparse to dense vector form (using the gensim corpus2dense fct)\n",
    "class MyCorpus(object):\n",
    "     def __iter__(self):\n",
    "            for line in wlp_bytext.rdd.map(lambda r: r[1]).collect():\n",
    "                yield dictionary.doc2bow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the corpus and turn it into a format that spark will like\n",
    "corpus = MyCorpus()\n",
    "#changing from sparse to dense representation\n",
    "data = sc.parallelize(corpus2dense(corpus,num_terms=len(dictionary.token2id),num_docs=dictionary.num_docs).T)\n",
    "#not sure this is entirely necessary but the data is transformed into spark dense vectors (maybe faster)\n",
    "parsedData = data.map(lambda line: Vectors.dense(line))\n",
    "#index documents with unique IDs\n",
    "corpus_rdd = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model, here it crashes, it should work though, I think it is juste because of a lack of resources\n",
    "ldas = LDA.train(corpus_rdd, k=10)\n",
    "\n",
    "#output topics, sadly there aren't any strings here, we need to map that to dictionary, would be even harder to do without gensim\n",
    "'''print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(10):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full gensim\n",
    "Same thing but entirely done with gensim. Very practical and concise. The word selection could even be done here, see the dictionary attributes `.filter_extremes` and `filter_n_most_frequent` [here](https://radimrehurek.com/gensim/corpora/dictionary.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = MyCorpus()\n",
    "ldag = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, update_every=1, chunksize=100, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldag.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
